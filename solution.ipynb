{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540b7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/Сборка шкаф-купе.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad122b",
   "metadata": {},
   "source": [
    "## ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7e278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api = os.getenv(\"api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e69f37",
   "metadata": {},
   "source": [
    "## PDF Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28f2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89f0ca3c-d213-4fc1-a7a2-19854a4344dd\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pdfplumber\n",
    "\n",
    "def pdf_to_images(pdf_path, resolution=300):\n",
    "    \"\"\"\n",
    "    Конвертирует все страницы PDF в изображения.\n",
    "    \n",
    "    Аргументы:\n",
    "        pdf_path (str): путь к PDF файлу\n",
    "        resolution (int): DPI для рендера страниц\n",
    "    \n",
    "    Возвращает:\n",
    "        (pdf_id, image_paths) где\n",
    "        pdf_id (str): уникальный id для папки\n",
    "        image_paths (list[str]): список путей к сохранённым изображениям\n",
    "    \"\"\"\n",
    "    pdf_id = str(uuid.uuid4())\n",
    "    output_dir = f\"images/{pdf_id}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            im = page.to_image(resolution=resolution)\n",
    "            img_filename = f\"{output_dir}/page{page_num}.png\"\n",
    "            im.save(img_filename, format=\"PNG\")\n",
    "            image_paths.append(img_filename)\n",
    "\n",
    "    return pdf_id, image_paths\n",
    "\n",
    "\n",
    "\n",
    "# пример вызова\n",
    "pdf_id, image_paths = pdf_to_images(pdf_path)\n",
    "print(pdf_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d577919",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201d06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a professional comic storyboard writer. \n",
    "Your task is to transform a given sequence of **images** (possibly from parsed PDF documents with mixed pictures and captions) into a cinematic comic script. \n",
    "\n",
    "Instructions:\n",
    "1. Carefully **describe each image** in English (visual content, characters, actions, mood, setting).\n",
    "2. Extract the main ideas and convert them into a sequence of **comic pages**, each page having exactly **4 panels** (so every page = 1 scene = 4 panels).\n",
    "3. Write everything in **English**.\n",
    "4. Output must be strictly in the following format (Python tuple):\n",
    "(\n",
    "    \"Unified cinematic style for the entire series: [one single descriptive paragraph describing art style, characters, settings, rendering details, coloring, film look, and atmosphere that apply to the entire comic].\",\n",
    "    [\n",
    "        \"COMIC_SCENE_01_NAME — 4-panel comic page. Panel 1: [description derived from the images]. Bubble: [dialogue]. Panel 2: [description]. Bubble: [dialogue]. Panel 3: [description]. Bubble: [dialogue]. Panel 4: [description]. Bubble: [dialogue].\",\n",
    "        \"COMIC_SCENE_02_NAME — 4-panel comic page, direct continuation. Panel 1: [description]. Bubble: [dialogue]. Panel 2: [description]. Bubble: [dialogue]. Panel 3: [description]. Bubble: [dialogue]. Panel 4: [description]. Bubble: [dialogue].\",\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "\n",
    "Rules:\n",
    "- Do not include any extra variables or explanations (no `unified_style_en = ...`, no `slides = ...`). Only return the tuple above.\n",
    "- Replace any literal image captions (e.g., “a photography of a judge’s gavel”) with **visual narrative and cinematic descriptions**.\n",
    "- Ensure dialogue is simple, conversational, and in English.\n",
    "- Maintain continuity: the same characters should appear across panels and scenes, with consistent roles and personalities.\n",
    "- Each scene = exactly one 4-panel comic page.\n",
    "- Maximum 3 comic scenes per run (12 panels total).\n",
    "- Output must be valid Python (tuple of a string + list of strings), parsable with `ast.literal_eval`.\n",
    "\n",
    "---\n",
    "SOURCE IMAGES:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae75283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import mimetypes\n",
    "from openai import OpenAI\n",
    "\n",
    "def images_to_message(paths, prompt):\n",
    "    if isinstance(paths, str):\n",
    "        paths = [paths]\n",
    "    \n",
    "    content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "    \n",
    "    for path in paths:\n",
    "        # Определяем MIME тип (по расширению)\n",
    "        mime_type, _ = mimetypes.guess_type(path)\n",
    "        if mime_type is None:\n",
    "            mime_type = \"image/png\"  # дефолт\n",
    "        \n",
    "        with open(path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "            image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        \n",
    "        data_url = f\"data:{mime_type};base64,{image_base64}\"\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": data_url}})\n",
    "    \n",
    "    return {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=api,\n",
    ")\n",
    "\n",
    "message = images_to_message(\n",
    "    image_paths, \n",
    "    prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2e6222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified style:\n",
      " Unified cinematic style for the entire series: A clean, contemporary graphic aesthetic with bold black linework and minimal shading, blending documentary-style furniture diagrams with cinematic storytelling. Characters are two collaborators, Alex (the steady designer) and Mira (the practical assistant), moving through a bright, modern workshop and a tidy home setting. The art favors wide establishing shots of the gamma sliding wardrobe, tight close-ups on hardware, and dynamic 3/4 perspective angles to emphasize scale and process. Color is restrained—mostly monochrome with subtle accent hues for emphasis (brand blue on logos or callouts). Lighting is bright and airy, with soft shadows to anchor depth, and panel transitions use clear, readable captions and simple, natural dialogue. The rhythm feels like a well-paced assembly manual turned into a short film: informative, confident, and friendly.\n",
      "\n",
      "Slides:\n",
      "\n",
      "Scene 1:\n",
      "SCENE_01_UNBOXING_AND_PLANNING — 4-panel comic page. Panel 1: In a bright, minimalist workshop, Alex stands beside a large, pristine Gamma Sliding Wardrobe concept sketch on the wall; the STEND logo is visible on the page. Mira enters with a tablet, ready to begin. Bubble: Alex: \"This is the Gamma wardrobe—sleek and sturdy.\" Panel 2: Mira studies the instruction sheet on the tablet, pointing at a diagram; the mood is focused and collaborative. Bubble: Mira: \"First, let's read the manual and check the parts.\" Panel 3: The two spread out the components on the floor: tall side panels, a top rail, and various panels arranged like a puzzle. Bubble: Alex: \"Base first, then the sides.\" Panel 4: A close-up on the tablet showing multilingual safety notes; Mira and Alex nod in agreement as they plan the steps. Bubble: Mira: \"Careful planning makes this easy.\"\n",
      "\n",
      "Scene 2:\n",
      "SCENE_02_FRAME_ASSEMBLY — 4-panel comic page. Panel 1: Alex and Mira lay out two large base panels on the floor, aligning holes with precision; tools sit in a tray nearby. Bubble: Mira: \"Bases laid out, nice and square.\" Panel 2: Alex uses a power drill to screw the corners; a zoomed-in inset highlights screws and washers being tightened. Bubble: Alex: \"Tighten the corners firmly.\" Panel 3: Mira slides the long drawer rails along the base, while Alex holds the frame steady; a row of rails becomes visible. Bubble: Mira: \"Rails in place, nice track alignment.\" Panel 4: The frame starts to take shape as the panels stand upright; both admire the growing structure. Bubble: Alex: \"Frame is coming together.\" Mira: \"Great team effort.\"\n",
      "\n",
      "Scene 3:\n",
      "SCENE_03_FINISHING_AND_INSTALL — 4-panel comic page. Panel 1: Two large doors progressively slide into their upper tracks; the wardrobe begins to resemble its final form. Bubble: Mira: \"Slide the doors into the tracks.\" Panel 2: Hinges and brackets are attached to the doors with the drill; a small inset shows the hardware being fastened. Bubble: Alex: \"Attach the hinges here.\" Panel 3: Shelves, dividers, and the top panel are installed; the interior layout becomes visible as compartments are created. Bubble: Mira: \"Now the shelves and top go in.\" Panel 4: The completed Gamma wardrobe stands in a bright room; Alex and Mira step back with satisfied smiles to admire their work. Bubble: Alex: \"All set! Time to fill it with clothes.\" Mira: \"It looks perfect.\"\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def extract_comic_tuple(text: str):\n",
    "    \"\"\"\n",
    "    Извлекает первый валидный Python-кортеж из ответа модели,\n",
    "    даже если вокруг есть лишний текст.\n",
    "    \"\"\"\n",
    "    # Находим участок от первой открывающей \"(\" до последней закрывающей \")\"\n",
    "    match = re.search(r\"\\(.*\\)\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Не найден кортеж в ответе модели.\")\n",
    "    \n",
    "    tuple_str = match.group(0)\n",
    "\n",
    "    try:\n",
    "        parsed = ast.literal_eval(tuple_str)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Ошибка при парсинге кортежа: {e}\\nИсходный текст:\\n{tuple_str}\")\n",
    "    \n",
    "    # Проверим, что структура правильная\n",
    "    if not (isinstance(parsed, tuple) and len(parsed) == 2):\n",
    "        raise ValueError(\"Найденный объект не является кортежем из 2 элементов.\")\n",
    "    if not isinstance(parsed[0], str):\n",
    "        raise ValueError(\"Первый элемент кортежа должен быть строкой (unified_style).\")\n",
    "    if not isinstance(parsed[1], list):\n",
    "        raise ValueError(\"Второй элемент кортежа должен быть списком (slides).\")\n",
    "    \n",
    "    return parsed\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"openai/gpt-5-nano\",\n",
    "            messages=[message],\n",
    "        )\n",
    "        llm_output = completion.choices[0].message.content\n",
    "        unified_style, slides = extract_comic_tuple(llm_output)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "text_slides = \" \".join(slides)\n",
    "print(\"Unified style:\\n\", unified_style)\n",
    "print(\"\\nSlides:\")\n",
    "for i, scene in enumerate(slides, 1):\n",
    "    print(f\"\\nScene {i}:\\n{scene}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd6c59",
   "metadata": {},
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5de5efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to decode/save base64 image: Incorrect padding\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class OpenRouterImageAPI:\n",
    "    def __init__(self, api_key, model=None, size=None):\n",
    "        default_headers = {}\n",
    "        if os.getenv(\"OPENROUTER_HTTP_REFERER\"):\n",
    "            default_headers[\"HTTP-Referer\"] = os.getenv(\"OPENROUTER_HTTP_REFERER\")\n",
    "        if os.getenv(\"OPENROUTER_X_TITLE\"):\n",
    "            default_headers[\"X-Title\"] = os.getenv(\"OPENROUTER_X_TITLE\")\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=api_key,\n",
    "            default_headers=default_headers or None,\n",
    "        )\n",
    "\n",
    "        # Keep for manual HTTP fallback\n",
    "        self.api_key = api_key\n",
    "        self.default_headers = default_headers or None\n",
    "\n",
    "        # Используй модель, которая поддерживает image output\n",
    "        self.model = model or os.getenv(\"OPENROUTER_IMAGE_MODEL\", \"google/gemini-2.5-flash-image-preview\")\n",
    "        self.size = size or os.getenv(\"OPENROUTER_IMAGE_SIZE\", \"1024x1024\")\n",
    "\n",
    "    def generate_image(self, prompt, num_images=1, output_dir=\"outputs\", prefix=\"slide\"):\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        logging.info(f\"Generating image via OpenRouter model='{self.model}' size='{self.size}'\")\n",
    "\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            extra_body={\n",
    "                \"modalities\": [\"image\", \"text\"],\n",
    "                \"n\": num_images,\n",
    "                \"size\": self.size,\n",
    "                \"response_format\": \"b64_json\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        saved_paths = []\n",
    "        timestamp = int(time.time())\n",
    "\n",
    "        image_counter = 0\n",
    "        for i, choice in enumerate(resp.choices, start=1):\n",
    "            content = getattr(choice.message, \"content\", None)\n",
    "            if not content:\n",
    "                logging.error(f\"No content in choice: {choice}\")\n",
    "                continue\n",
    "\n",
    "            # Normalize to iterable of blocks\n",
    "            blocks = content if isinstance(content, list) else [content]\n",
    "\n",
    "            for block in blocks:\n",
    "                b64 = None\n",
    "                url_to_fetch = None\n",
    "\n",
    "                if isinstance(block, dict):\n",
    "                    btype = block.get(\"type\") or block.get(\"kind\")\n",
    "                    # OpenRouter 'output_image' (most common)\n",
    "                    if btype in (\"output_image\", \"image\"):\n",
    "                        b64 = block.get(\"image_base64\") or block.get(\"b64_json\")\n",
    "                        # Some providers nest it\n",
    "                        if not b64 and isinstance(block.get(\"image\"), dict):\n",
    "                            b64 = block[\"image\"].get(\"b64_json\") or block[\"image\"].get(\"base64\")\n",
    "                    # Our previous handler for data URLs\n",
    "                    if btype == \"image_url\" and isinstance(block.get(\"image_url\"), dict):\n",
    "                        img_url = block[\"image_url\"].get(\"url\", \"\")\n",
    "                        if isinstance(img_url, str) and img_url.startswith(\"data:\"):\n",
    "                            try:\n",
    "                                _, b64 = img_url.split(\",\", 1)\n",
    "                            except Exception:\n",
    "                                b64 = None\n",
    "                        elif isinstance(img_url, str) and img_url.startswith(\"http\"):\n",
    "                            url_to_fetch = img_url\n",
    "                elif isinstance(block, str):\n",
    "                    text = block.strip()\n",
    "                    if text.startswith(\"data:\"):\n",
    "                        try:\n",
    "                            _, b64 = text.split(\",\", 1)\n",
    "                        except Exception:\n",
    "                            b64 = None\n",
    "                    else:\n",
    "                        # Heuristic: treat long strings as raw base64\n",
    "                        if len(text) > 100:\n",
    "                            b64 = text\n",
    "\n",
    "                # Save from base64 if available\n",
    "                if b64:\n",
    "                    try:\n",
    "                        image_bytes = base64.b64decode(b64)\n",
    "                        image_counter += 1\n",
    "                        file_path = Path(output_dir) / f\"{prefix}-{timestamp}-{image_counter}.png\"\n",
    "                        with open(file_path, \"wb\") as f:\n",
    "                            f.write(image_bytes)\n",
    "                        saved_paths.append(str(file_path))\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to decode/save base64 image: {e}\")\n",
    "                        continue\n",
    "\n",
    "                # Fallback: fetch via URL if provided\n",
    "                if url_to_fetch:\n",
    "                    try:\n",
    "                        r = requests.get(url_to_fetch, timeout=60)\n",
    "                        r.raise_for_status()\n",
    "                        image_counter += 1\n",
    "                        file_path = Path(output_dir) / f\"{prefix}-{timestamp}-{image_counter}.png\"\n",
    "                        with open(file_path, \"wb\") as f:\n",
    "                            f.write(r.content)\n",
    "                        saved_paths.append(str(file_path))\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to download image from URL: {e}\")\n",
    "                        continue\n",
    "\n",
    "        if not saved_paths:\n",
    "            # Deep fallback: scan the entire response object for base64 image strings\n",
    "            try:\n",
    "                def walk_collect_b64(value, out_list):\n",
    "                    if isinstance(value, dict):\n",
    "                        for k, v in value.items():\n",
    "                            # Common keys used by providers\n",
    "                            if k in (\"image_base64\", \"b64_json\", \"imageBytes\", \"image_base64_png\") and isinstance(v, str):\n",
    "                                out_list.append(v)\n",
    "                            # Any URL fields containing data URLs\n",
    "                            if k in (\"url\", \"image_url\") and isinstance(v, str) and v.startswith(\"data:\"):\n",
    "                                try:\n",
    "                                    _, b = v.split(\",\", 1)\n",
    "                                    out_list.append(b)\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                            else:\n",
    "                                walk_collect_b64(v, out_list)\n",
    "                    elif isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            walk_collect_b64(item, out_list)\n",
    "                    elif isinstance(value, str):\n",
    "                        text = value.strip()\n",
    "                        if text.startswith(\"data:\") and \",\" in text:\n",
    "                            try:\n",
    "                                _, b = text.split(\",\", 1)\n",
    "                                out_list.append(b)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        else:\n",
    "                            # Heuristic: very long base64-ish strings\n",
    "                            if len(text) > 500 and all(c.isalnum() or c in \"+/=\\n\\r\" for c in text[:100]):\n",
    "                                out_list.append(text)\n",
    "\n",
    "                raw_obj = None\n",
    "                try:\n",
    "                    raw_obj = resp.model_dump()\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        raw_json = getattr(resp, \"json\", None)\n",
    "                        if callable(raw_json):\n",
    "                            raw_obj = raw_json()\n",
    "                        else:\n",
    "                            raw_obj = json.loads(str(resp))\n",
    "                    except Exception:\n",
    "                        raw_obj = None\n",
    "\n",
    "                candidates = []\n",
    "                if raw_obj is not None:\n",
    "                    walk_collect_b64(raw_obj, candidates)\n",
    "\n",
    "                for idx, b64 in enumerate(candidates, start=1):\n",
    "                    try:\n",
    "                        image_bytes = base64.b64decode(b64)\n",
    "                        file_path = Path(output_dir) / f\"{prefix}-{timestamp}-fallback-{idx}.png\"\n",
    "                        with open(file_path, \"wb\") as f:\n",
    "                            f.write(image_bytes)\n",
    "                        saved_paths.append(str(file_path))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                logging.debug(f\"Fallback scan error: {e}\")\n",
    "\n",
    "        # Final fallback: call OpenRouter directly via HTTP to avoid SDK type quirks\n",
    "        if not saved_paths:\n",
    "            try:\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                }\n",
    "                if self.default_headers:\n",
    "                    headers.update(self.default_headers)\n",
    "                body = {\n",
    "                    \"model\": self.model,\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                    # Provider-specific hints are forwarded by OpenRouter\n",
    "                    \"modalities\": [\"image\", \"text\"],\n",
    "                    \"n\": num_images,\n",
    "                    \"size\": self.size,\n",
    "                    \"response_format\": \"b64_json\",\n",
    "                }\n",
    "                http_resp = requests.post(\n",
    "                    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers=headers,\n",
    "                    json=body,\n",
    "                    timeout=120,\n",
    "                )\n",
    "                http_resp.raise_for_status()\n",
    "                data = http_resp.json()\n",
    "\n",
    "                # Reuse collector\n",
    "                candidates = []\n",
    "                def walk_collect_b64_http(value, out_list):\n",
    "                    if isinstance(value, dict):\n",
    "                        for k, v in value.items():\n",
    "                            if k in (\"image_base64\", \"b64_json\", \"imageBytes\", \"image_base64_png\") and isinstance(v, str):\n",
    "                                out_list.append(v)\n",
    "                            if k in (\"url\", \"image_url\") and isinstance(v, str) and v.startswith(\"data:\"):\n",
    "                                try:\n",
    "                                    _, b = v.split(\",\", 1)\n",
    "                                    out_list.append(b)\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                            else:\n",
    "                                walk_collect_b64_http(v, out_list)\n",
    "                    elif isinstance(value, list):\n",
    "                        for item in value:\n",
    "                            walk_collect_b64_http(item, out_list)\n",
    "                    elif isinstance(value, str):\n",
    "                        text = value.strip()\n",
    "                        if text.startswith(\"data:\") and \",\" in text:\n",
    "                            try:\n",
    "                                _, b = text.split(\",\", 1)\n",
    "                                out_list.append(b)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                        elif len(text) > 500 and all(c.isalnum() or c in \"+/=\\n\\r\" for c in text[:100]):\n",
    "                            out_list.append(text)\n",
    "\n",
    "                walk_collect_b64_http(data, candidates)\n",
    "\n",
    "                for idx, b64 in enumerate(candidates, start=1):\n",
    "                    try:\n",
    "                        image_bytes = base64.b64decode(b64)\n",
    "                        file_path = Path(output_dir) / f\"{prefix}-{timestamp}-http-{idx}.png\"\n",
    "                        with open(file_path, \"wb\") as f:\n",
    "                            f.write(image_bytes)\n",
    "                        saved_paths.append(str(file_path))\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                logging.error(f\"HTTP fallback failed: {e}\")\n",
    "\n",
    "        if not saved_paths:\n",
    "            # Regex scan of any text representation for embedded base64\n",
    "            try:\n",
    "                import re\n",
    "                def extract_and_save_from_text(text: str, tag: str):\n",
    "                    local_saved = []\n",
    "                    if not text:\n",
    "                        return local_saved\n",
    "                    # data URL pattern first\n",
    "                    for m in re.finditer(r\"data:image/[^;]+;base64,([A-Za-z0-9+/=\\r\\n]+)\", text):\n",
    "                        b64 = m.group(1)\n",
    "                        try:\n",
    "                            image_bytes = base64.b64decode(b64)\n",
    "                            file_path = Path(output_dir) / f\"{prefix}-{timestamp}-scan-{tag}-{len(local_saved)+1}.png\"\n",
    "                            with open(file_path, \"wb\") as f:\n",
    "                                f.write(image_bytes)\n",
    "                            local_saved.append(str(file_path))\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                    # Generic long base64 chunks (PNG/JPEG often start with iVBOR or /9j/)\n",
    "                    for m in re.finditer(r\"(iVBOR|/9j/)[A-Za-z0-9+/=\\r\\n]{400,}\", text):\n",
    "                        b64 = m.group(0)\n",
    "                        try:\n",
    "                            image_bytes = base64.b64decode(b64)\n",
    "                            file_path = Path(output_dir) / f\"{prefix}-{timestamp}-scan-{tag}-{len(local_saved)+1}.png\"\n",
    "                            with open(file_path, \"wb\") as f:\n",
    "                                f.write(image_bytes)\n",
    "                            local_saved.append(str(file_path))\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                    return local_saved\n",
    "\n",
    "                text_repr = None\n",
    "                try:\n",
    "                    text_repr = resp.model_dump_json()  # may omit large blobs\n",
    "                except Exception:\n",
    "                    text_repr = str(resp)\n",
    "                saved_paths.extend(extract_and_save_from_text(text_repr, \"obj\"))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if not saved_paths:\n",
    "            raise Exception(\"Image generation returned no images\")\n",
    "\n",
    "        return saved_paths\n",
    "\n",
    "\n",
    "client = OpenRouterImageAPI(api, model=\"google/gemini-2.5-flash-image-preview\")\n",
    "Path(f\"outputs/{pdf_id}\").mkdir(parents=True, exist_ok=True)\n",
    "full_prompt = f\"{unified_style} {text_slides}\"\n",
    "try:\n",
    "    saved = client.generate_image(full_prompt, num_images=1, output_dir=f\"outputs/{pdf_id}\", prefix=f\"slide-{i}\")\n",
    "except Exception as e:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
